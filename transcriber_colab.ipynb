{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cadc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"GPU disponible :\", torch.cuda.is_available())\n",
    "print(\"Nom GPU :\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Aucun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fac7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/franckbirba/transcriber-cli.git\n",
    "%cd transcriber-cli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeab825",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = \"hf_...\"  # <-- Remplace ici par ton vrai token Hugging Face\n",
    "\n",
    "with open(\".env\", \"w\") as f:\n",
    "    f.write(f\"HUGGINGFACE_TOKEN={HF_TOKEN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_dir = \"/content/drive/MyDrive/transcription/input\"\n",
    "output_dir = \"/content/drive/MyDrive/transcription/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90237b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_all.py --input \"$input_dir\" --output \"$output_dir\" --gpu"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
